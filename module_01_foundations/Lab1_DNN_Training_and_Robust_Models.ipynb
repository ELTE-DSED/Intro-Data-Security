{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0be39552",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ELTE-DSED/Intro-Data-Security/blob/main/module_01_foundations/Lab1_DNN_Training_and_Robust_Models.ipynb)\n",
    "\n",
    "# **Lab 1: Deep Neural Network Training & Robust Models**\n",
    "\n",
    "**Course:** Introduction to Data Security Pr. (Master's Level)  \n",
    "**Module 1:** Foundations  \n",
    "**Estimated Time:** 90-120 minutes\n",
    "\n",
    "---\n",
    "In this notebook, we will use the basic training functionalities of [SecML-Torch](https://secml-torch.readthedocs.io/) to train a regular PyTorch Deep Neural Network (DNN) classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51b474",
   "metadata": {},
   "source": [
    "SecML-Torch (SecMLT) is an open-source Python library designed to facilitate research in the area of Adversarial Machine Learning (AML) and robustness evaluation. The library provides a simple yet powerful interface for generating various types of adversarial examples, as well as tools for evaluating the robustness of machine learning models against such attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0de37f",
   "metadata": {},
   "source": [
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Train** deep neural networks on standard image classification dataset (MNIST)\n",
    "2. **Evaluate** model performance using standard metrics (accuracy, loss)\n",
    "3. **Understand** the difference between standard models and robust models\n",
    "4. **Load** and compare pre-trained robust models\n",
    "5. **Establish** baseline models for subsequent security labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bdf34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e7c0a35",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "1. [Setup & Imports](#setup)\n",
    "2. [Part 1: Dataset Loading & Preprocessing](#part1)\n",
    "3. [Part 2: Training a Standard DNN](#part2)\n",
    "4. [Part 3: Evaluating Model Performance](#part3)\n",
    "5. [Part 4: Loading Pre-trained & Robust Models](#part4)\n",
    "6. [Conclusion & Next Steps](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd653195",
   "metadata": {},
   "source": [
    "## **Setup & Imports** <a name=\"setup\"></a>\n",
    "\n",
    "First, we'll install necessary libraries and import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c841f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install torch torchvision matplotlib numpy scikit-learn tqdm secml-torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1029eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68fd0b",
   "metadata": {},
   "source": [
    "## **Part 1: Dataset Loading & Preprocessing** <a name=\"part1\"></a>\n",
    "\n",
    "We'll work with **MNIST** (handwritten digits) as our primary dataset. MNIST is a standard benchmark for:\n",
    "- Image classification\n",
    "- Neural network training\n",
    "- Adversarial robustness research\n",
    "\n",
    "**Dataset Details:**\n",
    "- **Training samples:** 60,000\n",
    "- **Test samples:** 10,000\n",
    "- **Image size:** 28×28 grayscale\n",
    "- **Classes:** 10 (digits 0-9)\n",
    "\n",
    "We import the training and testing dataset of MNIST from `torchvision`, and provide them to the dedicated data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff32d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor and scale to [0, 1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of batches (train): {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfc1e9",
   "metadata": {},
   "source": [
    "### **Visualize Sample Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfa359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training samples\n",
    "def show_images(dataset, num_samples=10):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image, label = dataset[i]\n",
    "        # Denormalize for visualization\n",
    "        image = image * 0.3081 + 0.1307\n",
    "        axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd3cec",
   "metadata": {},
   "source": [
    "We will train a classifier for the MNIST dataset. First, we define the model as a `torch.nn.Module`, as usually done in the `torch` library. The model is a simple fully-connected network with three layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bec0cb",
   "metadata": {},
   "source": [
    "## **Part 2: Training a Standard DNN** <a name=\"part2\"></a>\n",
    "\n",
    "We'll implement a simple **fully connected network (MLP)** for MNIST classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9062822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(torch.nn.Module):\n",
    "    \"\"\"Simple fully connected network for MNIST classification.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 200)\n",
    "        self.fc2 = torch.nn.Linear(200, 200)\n",
    "        self.fc3 = torch.nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Initialize model\n",
    "net = MNISTNet().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65c59c",
   "metadata": {},
   "source": [
    "### **Train the Model**\n",
    "\n",
    "we initialize the optimizer to use for training the model. We’re using Adam with a learning rate of 1e-3, which is a good default choice for our neural network and then we will start using the `SecML-Torch` functionalities to train the previously-defined model on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure gradients are enabled (just in case they were disabled by a previous cell)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41cd605",
   "metadata": {},
   "source": [
    "We will use the class `secmlt.models.pytorch.base_pytorch_trainer.BasePyTorchTrainer` to prepare a training loop. This class implements the regular training loop which performs optimization steps (with the optimizer of choice) on a for loop on the batches of samples, for a given amount of epochs (passed as an input parameter). The trainer handles the forward pass, loss computation, backward pass, and parameter updates automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b986a",
   "metadata": {},
   "source": [
    "We wrap the model into a `secmlt.models.pytorch.base_pytorch_nn.BasePytorchClassifier` class, which provides the APIs to use models subclassing the `torch.nn.Module` within SecML-Torch. This wrapper doesn’t modify your model but adds methods that integrate with SecML-Torch’s ecosystem for attacks and defenses. Then, we can train our model by calling `model.train(dataloader=training_loader)`. This single line replaces the typical PyTorch training loop boilerplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "from secmlt.models.pytorch.base_pytorch_trainer import BasePyTorchTrainer\n",
    "\n",
    "\n",
    "# Training MNIST model\n",
    "trainer = BasePyTorchTrainer(optimizer=optimizer, epochs=1)\n",
    "model = BasePytorchClassifier(model=net, trainer=trainer)\n",
    "\n",
    "model.train(dataloader=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d886",
   "metadata": {},
   "source": [
    "## **Part 3: Evaluating Model Performance** <a name=\"part3\"></a>\n",
    "We can check how the model performs on the testing dataset by using the `secmlt.metrics.classification.Accuracy` wrapper. This provides the accuracy scoring loop that queries the model with all the batches and counts how many predictions are correct. The metric automatically handles device placement and batch aggregation, returning a single accuracy value for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secmlt.metrics.classification import Accuracy\n",
    "\n",
    "accuracy = Accuracy()(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d79f6",
   "metadata": {},
   "source": [
    "Finally, we can save our model weights with the torch saving functionalities. To get the model, we can access the model attribute of the `secmlt.models.pytorch.base_pytorch_nn.BasePytorchClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf15b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(\"models/mnist\")\n",
    "if not model_path.exists():\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.model.state_dict(), model_path / \"mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b004e7",
   "metadata": {},
   "source": [
    "After saving the model we can load it for further evaluations by simply using the `torch.load` method and wrap it again with `secmlt.models.pytorch.base_pytorch_nn.BasePytorchClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40278218",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_net = MNISTNet()\n",
    "model_weights_path = model_path / \"mnist_model.pt\"\n",
    "model_weights = torch.load(model_weights_path, map_location=\"cpu\")\n",
    "trained_net.eval()\n",
    "trained_net.load_state_dict(model_weights)\n",
    "trained_model = BasePytorchClassifier(model=trained_net, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9316c56",
   "metadata": {},
   "source": [
    "## **Part 4: Loading Pre-trained & Robust Models** <a name=\"part4\"></a>\n",
    "\n",
    "we will use the basic functionalities of SecML-Torch to import a pre-trained model from torchvision or a robust model from RobustBench. This demonstrates how SecML-Torch can wrap any PyTorch model, whether it's a standard pre-trained model or one specifically trained for adversarial robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0db85",
   "metadata": {},
   "source": [
    "### **4.1 Loading and Preprocessing an Image**\n",
    "\n",
    "We'll download a sample image and prepare it for inference using the standard ImageNet preprocessing pipeline: resize to 256, center-crop to 224, and convert to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import get_model\n",
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "img_url = (\n",
    "    \"https://raw.githubusercontent.com/ajschumacher/imagen/master/imagen/\"\n",
    "    \"n02342885_10908_hamster.jpg\"\n",
    " )\n",
    "labels_url = (\n",
    "    \"https://raw.githubusercontent.com/\"\n",
    "    \"anishathalye/imagenet-simple-labels/master/\"\n",
    "    \"imagenet-simple-labels.json\"\n",
    " )\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Download hamster image with timeout\n",
    "resp = requests.get(img_url, headers=headers, timeout=30)\n",
    "resp.raise_for_status()\n",
    "\n",
    "# Download ImageNet labels with timeout\n",
    "labels_resp = requests.get(labels_url, headers=headers, timeout=30)\n",
    "labels_resp.raise_for_status()\n",
    "\n",
    "imagenet_labels = json.loads(labels_resp.text)\n",
    "img = Image.open(io.BytesIO(resp.content)).convert(\"RGB\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Sample ImageNet Image\")\n",
    "plt.show()\n",
    "\n",
    "imagenet_input_tensor = imagenet_transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89300a08",
   "metadata": {},
   "source": [
    "### **4.2 Importing a Pre-trained Model from Torchvision**\n",
    "\n",
    "Now we’ll load a pre-trained Vision Transformer (ViT) model from torchvision. The model has been trained on ImageNet-1K and expects images preprocessed as shown above. We wrap it with BasePytorchClassifier to integrate it with SecML-Torch’s functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_net = get_model(\"vit_b_16\", weights=\"IMAGENET1K_V1\")\n",
    "imagenet_net.to(device)\n",
    "imagenet_net.eval()\n",
    "\n",
    "imagenet_model = BasePytorchClassifier(imagenet_net)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71658af3",
   "metadata": {},
   "source": [
    "### **4.3 Making Predictions with the Pre-trained Model**\n",
    "\n",
    "Let’s use the wrapped model to classify our image. The `predict` method handles the forward pass and returns the predicted class index. We’ll map this to the human-readable ImageNet label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_pred = imagenet_model.predict(imagenet_input_tensor.unsqueeze(0).to(device))\n",
    "imagenet_label = imagenet_labels[imagenet_pred.item()]\n",
    "print(f\"Predicted class index: {imagenet_pred.item()}\")\n",
    "print(f\"Predicted class label: {imagenet_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630a484",
   "metadata": {},
   "source": [
    "### **4.4 Loading a Robust Model from RobustBench**\n",
    "\n",
    "RobustBench provides models trained for adversarial robustness. We'll load a model robust to $L_\\infty$ perturbations and wrap it the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fc837",
   "metadata": {},
   "source": [
    "Before using models from RobustBench, we need to install the RobustBench package and its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceca308",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install git+https://github.com/RobustBench/robustbench.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustbench.utils import load_model\n",
    "\n",
    "robust_net = load_model(model_name=\"Salman2020Do_R18\", dataset=\"imagenet\", threat_model=\"Linf\")\n",
    "robust_net.to(device)\n",
    "robust_net.eval()\n",
    "\n",
    "robust_model = BasePytorchClassifier(robust_net)\n",
    "print(\"Robust model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c77ec",
   "metadata": {},
   "source": [
    "### **4.5 Comparing Predictions**\n",
    "\n",
    "Robust models may trade clean accuracy for resilience, but on this example both models should agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdf18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_pred = robust_model.predict(imagenet_input_tensor.unsqueeze(0).to(device))\n",
    "robust_label = imagenet_labels[robust_pred.item()]\n",
    "print(f\"Predicted class index: {robust_pred.item()}\")\n",
    "print(f\"Predicted class label: {robust_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fcbc7",
   "metadata": {},
   "source": [
    "## **Conclusion & Next Steps** <a name=\"conclusion\"></a>\n",
    "---\n",
    "\n",
    "### **What You Learned**\n",
    "\n",
    "- **Neural Network Training:** Built and trained a DNN from scratch  \n",
    "- **Model Evaluation:** Used accuracy \n",
    "- **Robust Models:** Understood the concept of adversarial robustness  \n",
    "- **Model Persistence:** Saved and loaded trained models  \n",
    "- **Baseline Establishment:** Created standard models for future attack labs  \n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "1. **Standard models** achieve high clean accuracy but are vulnerable to adversarial attacks\n",
    "2. **Robust models** trade some clean accuracy for adversarial resilience\n",
    "3. **Adversarial training** is the most effective defense but computationally expensive\n",
    "4. **Model architecture** affects both performance and robustness\n",
    "\n",
    "### **Preparing for Upcoming Labs**\n",
    "\n",
    "- **Module 2:** Implement and defend against evasion attacks\n",
    "- **Module 3-4:** Execute and detect poisoning attacks\n",
    "- **Module 5:** Create and mitigate sponge attacks\n",
    "- **Module 6:** Launch and prevent privacy attacks\n",
    "- **Module 7:** Generate and evaluate synthetic data\n",
    "- **Module 8:** Deploy comprehensive defense systems\n",
    "\n",
    "### **Additional Resources**\n",
    "\n",
    "**Foundational Papers:**\n",
    "- [Explaining and Harnessing Adversarial Examples (Goodfellow et al., 2015)](https://arxiv.org/abs/1412.6572)\n",
    "- [Towards Deep Learning Models Resistant to Adversarial Attacks (Madry et al., 2018)](https://arxiv.org/abs/1706.06083)\n",
    "- [Adversarial Examples Are Not Bugs, They Are Features (Ilyas et al., 2019)](https://arxiv.org/abs/1905.02175)\n",
    "- [SoK: Security and Privacy in Machine Learning (Papernot et al., 2018)](https://ieeexplore.ieee.org/document/8406613)\n",
    "- [The NIST Adversarial ML Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)\n",
    "\n",
    "**Industry Standards:**\n",
    "- MITRE ATLAS: Adversarial Threat Landscape for AI Systems\n",
    "- OWASP Machine Learning Security Top 10\n",
    "- ISO/IEC 24029: AI Trustworthiness\n",
    "\n",
    "**Tools & Frameworks:**\n",
    "- [SecML-Torch](https://secml-torch.readthedocs.io/)\n",
    "- [Microsoft Threat Modeling Tool](https://www.microsoft.com/en-us/securityengineering/sdl/threatmodeling)\n",
    "- [Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
